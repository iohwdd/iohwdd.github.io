[{"categories":null,"content":"内存区域 jdk1.8之后JVM的内存结构： 线程共享：堆[字符串常量池] 线程私有：程序计数器、虚拟机栈、本地方法栈 本地内存：元空间[运行时常量池(各种字面量和符合引用的常量池表)]、直接内存 ","date":"2024-11-19","objectID":"/jvm/:1:0","tags":null,"title":"JVM","uri":"/jvm/"},{"categories":null,"content":"程序计数器 指示线程下一条执行的命令。与线程绑定同生共死 作用： 实现代码流程控制（分支、循环等） 在线程切换恢复之后，能够定位到接下来要执行的代码位置 ","date":"2024-11-19","objectID":"/jvm/:1:1","tags":null,"title":"JVM","uri":"/jvm/"},{"categories":null,"content":"虚拟机栈 方法调用会形成一个栈帧，加入到虚拟机栈中，完成调用后出栈。 栈帧：包含了局部变量表、操作数表、动态链接、方法返回链接 局部变量表：存放编译期可知的各种数据类型 操作数栈：存放方法调用时产生的中间结果或临时变量 动态链接：当一个方法需要调用另外一个方法时，需要将符合引用转化为内存地址的直接引用。这个过程就是动态链接 可能出现的异常： OOM：容量太大，申请不到 StackFlow：栈的深度太大（递归） ","date":"2024-11-19","objectID":"/jvm/:1:2","tags":null,"title":"JVM","uri":"/jvm/"},{"categories":null,"content":"本地方法栈 调用os中的方法所用到的栈 ","date":"2024-11-19","objectID":"/jvm/:1:3","tags":null,"title":"JVM","uri":"/jvm/"},{"categories":null,"content":"堆 在jdk1.8之后，堆划分为新生代、老年代、元空间（1.7之前是永久代，被此替换）。堆空间是存放几乎所有对象实例的地方，对于某些方法中对象引用没有被返回或者没有被外部使用的（jdk1.7之后开启的逃逸分析），就直接在栈上分配内存。 新生代对象在Eden中，在新生代进行一次垃圾回收后，还存活的对象晋升至s1或s0，并将年龄设置为1。当年龄达到15（可以自己设置-XX:MaxTenuringThreshold ，最大为15，因为对象头中只提供了4位标识年龄）时，晋升至老年代。 补充最大年龄相关知识： 当survivor区某个年龄的数量超过了50%（可以通过-XX:TargetSurvivorRatio=percent 设置）时，会将晋升年龄与这个年龄取一个最小值作为新的晋升年龄。 可能出现的异常： Java heap space：申请不到足够内存了 GC Overhead Limit Exceeded：垃圾回收后仍然没有足够的内存。也就是说大部分对象都无法被垃圾回收。 ","date":"2024-11-19","objectID":"/jvm/:1:4","tags":null,"title":"JVM","uri":"/jvm/"},{"categories":null,"content":"方法区 方法区是一个抽象概念，可以理解为一个接口，元空间是方法区的实现 该空间，主要存放类的元信息，如类信息、字段信息、静态变量等。当调用方法时使用到的类没有被加载（也就是元空间没有），就会先进行类加载，然后存入到元空间中。也就是说，类加载是懒加载。 元空间使用的是本地内存，默认没有使用上限 可以通过-XX:MetaspaceSize=N 设置初始大小，-XX:MaxMetaspaceSize=N 设置最大大小 ","date":"2024-11-19","objectID":"/jvm/:1:5","tags":null,"title":"JVM","uri":"/jvm/"},{"categories":null,"content":"类初始化和类加载 创建对象的过程 类加载检查（没有加载过就先加载类） 在堆中分配空间，有两种方式 指针碰撞 适用情况：堆内存规整，没有碎片 原理：用过的内存放一边，没用过的放在另外一边，中间有一个分界指针，只要想着没用过的内存方向将指针移动对象内存大小即可 GC收集器：Serial, ParNew 空闲列表 适用情况：堆内存不规整，有碎片 原理：虚拟机维护一个列表记录哪些内存可用。在分配时找一块足够大的内存块分配给对象实例 GC收集器：CMS 内存分配并发问题，基于下面两种保证线程安全： CAS+失败重试：CAS为乐观锁的一种实现，发生冲突就会重试 TLAB：为每一个线程在Eden区分配一块内存，在线程中的对象创建时，先在TLAB创建，该区域用完时再采用上述的CAS进行内存分配 初始化为0值 设置对象头（标注哪个类的示例，用了什么锁等等） 执行构造器 对象的生命周期 创建：在堆中实例化 使用：被引用执行相应操作 销毁：不再被引用时，被垃圾回收，释放内存空间 对象的内存布局 对象头、实例数据、对齐填充 对象头： 标记字段：存储哈希码、GC年龄、锁标志等 类型指针：指向类元数据的指针，虚拟机凭此确定是哪个类的实例 实例数据：存放对象真正的有效信息，各种字段的内容 对齐填充：仅仅起到一个内存对齐的作用。虚拟机要求对象的其实地址必须是8的整数倍 对象的访问定位 句柄 直接指针 句柄的好处是在类移到时，只需要改变句柄中的实例指针，而reference本身不需要改；直接指针好处就是速度快，节省一次指针定位的开销。 类加载器 自顶向下分：启动类加载器（加载java核心库） -\u003e 扩展类加载器 （加载扩展目录下的jar包和类库）-\u003e 应用程序类加载器 （我们平时写的java程序）-\u003e 用户自定义类加载器 双亲委派模型：当类加载器收到类加载请求时，不会立马自己开始加载，而是交给父类加载器加载，若父加载器反馈自己无法完成这个加载请求，子加载器才会尝试自己去加载。 保证了类的唯一性，避免重复加载java类型 类加载过程 加载 将二进制流转化成方法区运行时的数据结构，在内存中生成一个代表类的Class对象 链接 验证 验证class文件中字节流的信息是否符合当前虚拟机的要求 准备 给静态字段分配内存，并设置默认值 解析 将常量池中的符合引用替换为直接引用 初始化 执行类的构造方法（编译器自动生成的） ","date":"2024-11-19","objectID":"/jvm/:2:0","tags":null,"title":"JVM","uri":"/jvm/"},{"categories":null,"content":"垃圾回收 ","date":"2024-11-19","objectID":"/jvm/:3:0","tags":null,"title":"JVM","uri":"/jvm/"},{"categories":null,"content":"死亡对象判断方法 引用计数法 给对象添加一个引用计数器，当有一个地方引用它计数器+1，当引用失效计数器-1。通过判断是否为0判断是否不再被引用。 缺陷：循环依赖的类即使不被其它地方引用，也无法识别回收 可达性分析算法 以GC ROOTS的对象为起点，向下搜索引用链，不在引用链上的对象则是不可用的对象，需要被回收。 引用类型总结 强引用：不会被垃圾回收 软引用：可有可无的对象。如果内存足够不会被回收，不够了就会回收 弱引用：一旦发生垃圾回收，该引用类型的对象都会被回收 虚引用：主要用来跟踪垃圾回收活动，必须与引用队列联合使用 判断一个类是无用的类 满足下面三个条件 该类所有的实例都已经被垃圾回收 该类的加载器已经被回收 没有地方使用该类的Class，如进行反射 ","date":"2024-11-19","objectID":"/jvm/:3:1","tags":null,"title":"JVM","uri":"/jvm/"},{"categories":null,"content":"垃圾回收算法 标记-清除 标记存活对象（可达对象），对未标记的对象进行清理。 缺点：产生内存碎片，效率低 标记-复制 将内存分为大小相同的两块，当其中一块用完时，将其中存活的对象集中分配到另一块，然后再整个清理该内存块。 缺点：内存缩小一半，如果存活对象量大，效率低 标记-整理 ​ 将标记的对象整理在一块连续集中的空间（集中在一端），清理边 界外的内存 ","date":"2024-11-19","objectID":"/jvm/:3:2","tags":null,"title":"JVM","uri":"/jvm/"},{"categories":null,"content":"垃圾收集器 Serial 单线程执行垃圾回收，并且会STW（用户线程暂停） ParNew serial的多线程版本，提高了效率 Parallel Scavnenge 类似ParNew，就是关注点在提高吞吐量（高效率利用CPU，尽可能少占用用户代码执行时间） CMS 旨在尽可能减少停顿时间，是并发收集器（几乎与用户线程同时工作，没有STW），采用标记-清除算法。 初始标记：标记直接与root相连的对象 并发标记：跟在垃圾回收时，引用发生更新的地方 重新标记：重新标记用户程序继续运行而导致标记产生变动的那一部分对象的标记记录 并发清除：开启用户线程，同时GC线程开始清扫 缺点：对CPU敏感，产生碎片 G1 采用标记-整理算法，低停顿时间，高吞吐量。 可以让使用者明确在指定M毫秒的时间内，消耗在垃圾收集器上的时间不得超过N毫秒。 初始标记 并发标记 最终标记 筛选回收 该收集器会在后台维护一个优先列表，每次根据收集时间，选择回收价值最大的Region，效率高。 ","date":"2024-11-19","objectID":"/jvm/:3:3","tags":null,"title":"JVM","uri":"/jvm/"},{"categories":null,"content":" title = ‘Mysql’ date = 2024-11-19T22:02:00+08:00 draft = true 索引 innodb存储数据： 以数据页的形式存储，数据页内拆分了若干组，组的引入是为了建立页目录，页目录记录的就是各个组的主键最大的位置，达到快速定位的效果。 b+树存储数据 每一个节点是一个数据页，只有叶子节点存放数据，非叶子节点存放目录项作为索引 Q：为什么采用B+数作为索引 A： 普通二叉树在极端情况下变成链表，查询效率低。 平衡二叉树和红黑树随着数据量的增加，树的高度也会增加，因此会增加磁盘IO，影响整体查询效率。 然后相比b树（多叉树）呢，b+树具有以下特点 只有叶子节点才会存放实际数据，非叶子节点只存放索引 所有索引都会在叶子节点出现，叶子节点直接构成一个有序链表（凭此就天然适合范围查询） 非叶子节点有多少个子节点就有多少索引。 非叶子节点也会存在子节点中，且是子节点中所有索引的最小（或最大） 对于使用情况： 单点查询 b+树非叶子节点只存放索引，在相同数据量的情况下，相比b树既存索引又存数据，b+树的非叶子节点可以存放更多的索引，因此b+树比b树更矮胖，查询底层节点的磁盘IO次数少（树低，深度浅）。 插入和删除效率 由于b+树存在大量的冗余节点，删除一个节点的时候，可以直接从叶子节点删除。而b树，删除一个节点可能会导致树结构的复制变化。对于插入也一样，有冗余节点，可能存在节点的分裂（如果节点饱和），但是最多只涉及一条路径。而且b+树自动平衡，不需要复杂的算法，类似红黑树的旋转操作等。因此b树的插入删除效率更高 范围查询 b+树的所有叶子节点有一个链表进行连接，且是有序的，支持范围查询 聚簇索引（通常为主键索引），叶子确定存放的是数据；而二级索引，叶子节点存放的是主键值，所以通过二级索引查数据时，还需要通过查找到的主键值，再根据主键索引（聚簇索引）找到数据，这就是回表操作。 覆盖索引： 当使用联合索引查询时，若需要查询的字段都包含在联合索引中，则不需要进行回表操作，直接就能够返回想要的数据。 事务 四大特性：原子性（undo kog）、一致性、隔离性（MVCC）、持久性（redo log） 并行事务可能产生的问题：脏读、不可重复读、幻读 隔离级别：读未提交、读已提交、可重复读、串行化 MVCC（多版本并发控制），维护一个版本链，实现读已提交与可重复读 innodb通过Read View实现MVCC Read View： 记录四个字段 事务id -\u003e creator_trx_id 当前活跃但未提交的事务id列表 -\u003e m_ids 活跃且月提交事务中最小的事务id -\u003e min_trx_id 未来分配给新事务的事务id -\u003e max_trx_id 记录的更新，会通过undo log形成一个版本链，链中每条记录都记录了事务的id。通过找到小于min_trx_id的第一条记录即可能到最新的且是已提交事务的记录。 可重复读是在事务开启时创建一个Read View，一直沿用到事务结束 而读提交则是每在执行select语句之前都会更新一次Read View，这样就可以确保能够读到新的已提交的事务。 锁 全局锁：整个数据库只能读了 表级锁： 表锁 元数据锁 -\u003e 锁的是表结构，读时不能改，改时不能读 意向锁 在给行数据加上共享锁/独占锁时，都要先给表加上意向共享/独占锁。所以，这个锁可以快速判断表记录是否还要共享/独占锁 行级锁： record lock 记录锁 顾名思义，对某一条记录加锁，有共享锁与独占锁之分 gap lock 间隙锁 对一个范围内加锁，是开区间 next-key 临键锁 对一个范围内加锁，左开右闭，可以理解为间隙锁+记录锁 插入意向锁 当想在间隙锁范围内插入数据，就会生成插入意向锁，会阻塞等待直到间隙锁释放，再插入数据 间隙锁与临键锁是为了解决幻读问题而引出的。 如何加行级锁？分下面几种情况 唯一索引等值查询： 记录存在。临键锁退化成记录锁，因为此时仅凭记录锁即可避免幻读问题，由于唯一索引的主键冲突机制，保证数据唯一性，然后加记录锁可以避免其它事务去删除该记录 记录不存在。临键锁退化成间隙锁。区间范围为恰好能包裹住改记录的区间，如查找id=2，且不存在，然后数据库中只有id=1与id=5的数据，那么区间就是（1，5），能包裹住2 唯一索引范围查询 非唯一索引等值查询 非唯一索引范围查询 日志 三种日志：undo log、redo log、bin log ","date":"0001-01-01","objectID":"/mysql/:0:0","tags":null,"title":"","uri":"/mysql/"},{"categories":null,"content":"undo log 主要是用来实现事务的原子性，用于事务回滚与MVCC。 比如进行一条更新操作语句时，在更新之前（事务提交前）会把旧数据写入undo log日志文件，如果事务出现异常，可以根据该日志文件进行回滚。 buffer pool 基于内存的缓存区 读取数据时，会从磁盘中读取数据页到内存中，在内存中修改完后不会直接写回磁盘，而是会将数据页缓存在inno存储引擎中的buffer pool中，记作缓存页。此时缓存页与磁盘中的数据并不一致，变为脏页。 innoDB引擎会在适当的时候将脏页刷新到磁盘中，这就是WAL技术，写操作不会立即写到磁盘上，而是先写日志，后面在合适的时机再写到磁盘上。 这样可以提高数据库的读写性能（减少磁盘IO）。 这个缓存区不仅仅只缓存数据页，还包括了索引页，undo页等，下面是该缓存区的内存模型： ","date":"0001-01-01","objectID":"/mysql/:1:0","tags":null,"title":"","uri":"/mysql/"},{"categories":null,"content":"redo log 主要是用于实现事务的持久性，在系统故障如停电，恢复后能够恢复数据。在事务提交后，都会向该日志记录数据页进行了什么操作，像XXX数据库对XXX表进行了XXX操作这种详细操作信息。 产生的redo log不会立即写入磁盘，会先写入redo log buffer，后续再持久化到磁盘中 有这么几个写入磁盘的时机（刷盘时机）： mysql正常关闭 redo log buffer写入量大于内存空间的一般 后台线程每隔1s （这种情况对应innodb_flush_log_at_trx_commit = 0 或 2 事务提交后（这种情况对应innodb_flush_log_at_trx_commit = 1 参数为0： 每次事务提交时，不做操作。1s后，OS通过调用write()写入page cache，然后调用fsync()持久化到磁盘 参数为2： 每次事务提交时，将redo log buffer里的redo log 写入 page cache。1s后，调用fsync()持久化到磁盘 写入方式 四个首尾相连的日志文件，循环写，已刷盘的部分会擦除。 因此redo log日志文件上始终保持的是未刷盘的日志（也就是说脏页数据还每更新到磁盘）。 在mysql服务宕机的情况下，恢复启动时可直接执行redo log上未刷盘的日志，达到数据恢复的目的。 Q：为什么bin log日志不能用于mysql宕机后进行数据恢复 A：bin log是不知道哪些数据是要恢复的，不知道从哪里开始。而redo log，对于那些未刷盘的日志，就是尚未更新至磁盘中的数据，也就是要恢复的数据。 ","date":"0001-01-01","objectID":"/mysql/:2:0","tags":null,"title":"","uri":"/mysql/"},{"categories":null,"content":"bin log 用Mysql里Server层产生的日志，主要用于数据备份和主从复制，上面两种日志都是基于innodb引擎的。 跟redo log有什么区别？ 写入方式不同 redo循环写，只保存未被刷盘的脏页日志 bin追加写，写满了新建一个文件继续写。也就是说这个日志保存了所有的mysql变化，这样当然可以用来数据备份、主从复制了（从节点同步时，都会先情况从节点的数据，再根据bin log日志文件进行复制） 用途不同 一个用于崩溃恢复 一个同于数据备份、主从复制 bin log不能拆开，必须保证一次性写入。 mysq为每个线程都会引入一个bin log cache，在事务提交时，会把每个线程bin log cache完整写入（通过OS里的wirte）到bin log文件并清空bin log cache。后续os再调用fsync()持久化到磁盘 三种文件格式 statement（默认） 记录每一条修改数据的SQL。主从同步根据SQL语句重现。 存在的问题：若记录的SQL含有动态函数，如now()，当在从库运行时结果会与主库中的数据不一致 row 记录行数据的变化。 存在的问题：若一条update语句批量更新了好多行的数据，那么该文件格式下会记录每一行的数据变化，导致binlog文件过大 mixed 上述两种混合。 根据不同的情况自动使用statement模式或row模式 写入方式 追加写，写满一个就创建新的文件写。保存的是全量的日志。 ","date":"0001-01-01","objectID":"/mysql/:3:0","tags":null,"title":"","uri":"/mysql/"},{"categories":null,"content":"两阶段提交 如何保证 MySQL 宕机后 redolog 与 binlog 都写入到本地？ 因为 redolog 与 binlog 是两个独立的运行逻辑，宕机时可能存在一方写入成功一方还未来得及写入的情况。MySQL 解决这种情况引入了两阶段提交 当事务提交时，MySQL 内部会开启一个 xa 事务，分两阶段完成 xa 事务的提交 1.准备阶段。先让 redolog 写入磁盘后，通知 MySQL server 成功了 2.提交阶段。先让 binlog 写入磁盘后，通知 MySQL server 成功了，接着将 redolog 日志状态设置为 commit，最后通知 MySQL server 都写入成功了 ","date":"0001-01-01","objectID":"/mysql/:4:0","tags":null,"title":"","uri":"/mysql/"},{"categories":null,"content":" title = ‘Redis’ date = 2024-11-26T17:18:25+08:00 draft = false 数据类型 String 底层实现：SDS，相比于c语言中的string有以下优点 可以保存除文本外的音视频图片信息。底层以二进制形式的数据保存至buf[]中，因此可以存音视频图片等二进制文件信息 查询字符串长度的时间复杂度为O(1)。因为底层记录了字符串的长度大小 高效拼接字符串，且之前会检查容量是否足够，避免缓冲区溢出 应用场景 存Json格式的对象信息 计数器 当key为整数时，提供了相关的api能对整数进行简单的增值降值操作。可以实现点赞/转发/访问数量等 分布式锁 set 命令有个参数 NX 可以实现key值不存在时成功插入，存在时插入失败。可对应key存在时，对应加锁失败，不存在时对应加锁成功。 对于解锁的过程，有两个步骤：判断锁的unique_value是否为加锁的客户端、删除lock_key锁。这时就需要lua脚本保证解锁的原子性。 共享session 当有多个服务器时，同一个用户可能每次访问不同的服务器，因而每次获取到的session不一致。可以通过在redis中统一存储sessionId，每个服务器都与redis建立连接，每个服务器都只会去同一个redis中获取session信息 List 底层实现：老版本是双向链表或压缩链表，redis 3.2 之后则统一由quicklist实现 应用场景： 消息队列 消息有序性：lpush+brpop实现（rpush+blpop也可）。使用brpop不使用rpop的原因是，brpop为阻塞式取数据，如果列表中没有数据时会阻塞等待直到有数据过来。如果用rpop，就需要消费者死循环不断去列表中获取，这很消耗cpu资源。 处理重复消息：给消息附加上一个全局唯一id标识，消费者消费之前判断是否消息过这条消息 可靠性：BRPOPLPUSH，消费者从list读取消息时，同时会将该消息写道另外一个list（备份list）。这样即使消费者在处理消息时宕机了，重启可以从备份list获取消息重新处理 ​ 不过上述方式实现的消息队列，每条消息只能被一个消费者消费 Hash 底层实现：老版本是压缩链表或哈希表，redis 7.0之后统一由listpack实现 应用场景： 购物车 用户id + 商品id:购买数量，刚好构成了购物车的三要素。 以用户id为key，商品id:购买数量键值对为value，存入hash中即可 Set 有序的、元素不可重复的集合 底层实现：整数集合或哈希表 应用场景： 点赞 与点赞相关的业务：数量、只能点赞一次、获取点赞的用户 共同关注 交集。另外利用差集，可以给对方推荐自己关注的公众号 抽奖活动 使用srandmember实现可重复中奖 使用spop实现不可重复中奖 ZSet 有序的、元素不可重复的集合 底层实现：老版本压缩列表或跳表实现，redis 7.0之后由listpack实现 应用场景： 排行榜 电话、姓名排序 ZRANGEBYLEX和 ZREVRANGEBYLEX实现，分数必须相同，设置为0即可。 跳表 是一个有序链表，查询复杂度为logn。 通过在原始链表上面增加索引，索引指向下下个元素，一级、二级索引以此类推。查询元素时先从最高层的索引开始查询，不在范围内就向下查询。 Geo 底层实现：就是Zsort，只是将经纬度信息进行编码实现了到权重分数的转换 应用场景： 滴滴叫车 搜索附件车辆 BitMap 底层实现：底层是用string类型实现的数据结构，string类型会将数据最终保存为二进制字节数组buf[],所以可以把每个bit位利用起来就可以当成一个bitmap 应用场景 用户签到：月签到天数（一个用户一个bitmap）、七天连续签到（一天一个bitmap，多个bitmap进行\u0026操作） 判断用户登录状态 持久化 ","date":"0001-01-01","objectID":"/redis/:0:0","tags":null,"title":"","uri":"/redis/"},{"categories":null,"content":"AOF日志 通过在客户端在redis中执行写命令之后，会将写命令追加到AOF日志文件，这样一来AOF日志文件保存了所有的写命令。系统异常造成数据丢失时，可通过执行AOF日志中的命令完成数据恢复。 Q：为什么要在执行写命令之后再写入AOF？ A：执行命令时会检查语法问题，避免写入时还要检查语法是否正确 三种写回策略 每执行一条写命令不会立即写入磁盘中的AOF文件，而是先写入缓冲区。后续由操作系统将缓冲区的内容追加到AOF文件。具体写回的策略有以下三种 Always：每执行一个命令，os就将该命令追加到AOF EverySec： 每隔1s，将缓冲区的内容追加到AOF No： 完全交由os决定什么时候写入AOF 可靠性：Always 高性能：No 运行数据丢一点，又想性能高：No AOF重写机制 当AOF文件很大达到一定阈值时，会触发重写机制。重写机制就是读取当前redis数据库中所有的键值对，每个键值对形成一条写命令，写入新的AOF文件中，最后更名替换旧的AOF文件。 AOF后台重写 为避免AOF重写在主线程运行造成阻塞，采用子进程完成AOF的重写。 Q：为什么不是子线程而是子进程？ A：多线程之间会共享数据，在修改共享内存数据时需要通过加锁保证数据的安全，这样就会降低性能。而使用子进程，父子进程是共享内存数据的，不过这个子进程只能以只读的方式。当父子进程任意一方修改了共享内存，就会发送写时复制，于是父子进程都有了独立的数据副本，就不用加锁来保证数据安全。 如果在子进程进行AOF重写的同时，主进程又修改了key-value，那么会导致两个问题，一个是子进程的数据跟主进程数据不一致；另一个是若是个bigkey，会造成主进程阻塞。为了解决这个问题，redis在重写期间，在执行一条写命令之后，会将其写入到AOF缓冲区和AOF重写缓冲区 子进程完成重写操作后，会向父进程发送信号，父进程接收到信号后，会执行信号处理函数，这个函数执行将AOF重写缓冲区的内容追加到新的AOF文件中，新的AOF文件更名覆盖旧的AOF文件，完成AOF后台重写。 AOF做持久化的缺点 因为redis执行命令由单线程执行，如果AOF文件很大，这个恢复的过程就会很慢 ","date":"0001-01-01","objectID":"/redis/:1:0","tags":null,"title":"","uri":"/redis/"},{"categories":null,"content":"RDB快照 以二进制文件的形式存储redis数据库某一时刻的数据快照。使用save和bgsave两个命令生成RDB文件，其中后者是创建子进程执行。每次在服务器启动时自动执行，也可以修改配置文件修改执行频次。该方式执行效率高于AOF日志。 如果生成RDB快照时，数据被修改的话是无法更新至RDB快照中的，但是可以通过缓冲区追加到AOF日志文件中。 RDB执行频率低会导致数据丢失多，频率高导致写入磁盘和创建子进程带来额外的开销。开启混合持久化功能（发送在AOF日志重写过程），aof-use-rdb-preamble yes ，在重写日志时，会以RBD方式写入到AOF文件中，再将重写缓冲区的增量命令追加到AOF文件中。写入完成后，会通知主线程新的还要RDB和AOF格式的AOF文件替换旧的AOF文件。 如此前半部分是RDB格式的全量数据，后半部分是AOF格式的增量数据，使得数据更少丢失。 ","date":"0001-01-01","objectID":"/redis/:2:0","tags":null,"title":"","uri":"/redis/"},{"categories":null,"content":"大key对持久化的影响 对于AOF日志持久化： 只会影响Alawyas写回策略，因为每执行一个写命令就向AOF日志（立刻执行fsync）追加命令。如果这个key很大，就会造成主线程阻塞。 另外两种，EverySec是先将命令写入内核缓冲区，每个1s将缓冲区内容写回硬盘，是创建一个异步任务执行fsync；No永远不会执行fsync。 对AOF重写与RDB快照的影响： AOF重写与生成RDB快照都会通过fork（）创建一个子进程执行任务。在创建子进程的过程中，os会把操作系统的页表复制给子进程。如果页表很大，这个过程会很耗时，因此执行fork()时就会有阻塞的现象。 在AOF重写过程中，主进程修改key-value时会发生写时复制，会把物理内存复制一份。由于大key占用物理内存大，这一过程也是比较耗时的。于是父进程就会阻塞 定时检查大key，删除大key使用unlink，该命令是异步的 过期删除于内存淘汰策略 ","date":"0001-01-01","objectID":"/redis/:3:0","tags":null,"title":"","uri":"/redis/"},{"categories":null,"content":"过期删除 redis在给一个键设置过期时间时，会向过期字典中加入键与过期时间。 有以下三种删除策略： 定时删除 在设置key的过期时间时同时创建一个定时事件，执行key的删除操作 优点：保证key尽快被删除，对内存最友好 确定：在key比较多的情况下，占用cpu过多的资源 惰性删除 每次访问一个key时，都会先检查是否过期，过期就删除 lazyfree_lazy_expire true 优点：每次访问时才会检查是否过期，对cpu友好 缺点：可能某一个key很久都不会被访问，那么就会一直存在于内存中，造成内存空间浪费 定期删除 每隔一段时间，会从redis中随机拿出一定数量的key进行检查，删除其中过期的key。若过期的数量达到一定比例则会继续新的一轮。 hz 10 每10s执行一次 优点：可以通过限制操作上限时间和频率，减少对cpu的影响 缺点：难以确定操作执行时长和频率。太频繁，像定时删除；太少，像惰性删除 ","date":"0001-01-01","objectID":"/redis/:4:0","tags":null,"title":"","uri":"/redis/"},{"categories":null,"content":"内存淘汰 当redis中存储的数据量达到上限时，就会根据内存淘汰策略删除一些key。有下面这些淘汰策略： 缓存 ","date":"0001-01-01","objectID":"/redis/:5:0","tags":null,"title":"","uri":"/redis/"},{"categories":null,"content":"雪崩 原因：大量缓存几乎同时失效，导致大量请求访问数据库，把数据库整垮 解决措施： 分散缓存过期时间，给缓存过期时间加上一个随机数 让缓存不失效，由后端主动更新缓存 使用互斥锁，如果发现缓存不在redis里，加个互斥锁，保证同一时间只有一个请求构建缓存（从数据读，再更新到redis） ","date":"0001-01-01","objectID":"/redis/:6:0","tags":null,"title":"","uri":"/redis/"},{"categories":null,"content":"击穿 原因：热点缓存失效，大量请求访问数据库，把数据库整垮。其实也可以看作雪崩的一种情况。 解决措施： 互斥锁 不给热点数据设置过期时间，后台同步更新 ","date":"0001-01-01","objectID":"/redis/:7:0","tags":null,"title":"","uri":"/redis/"},{"categories":null,"content":"穿透 原因：缓存中没有，数据库中也没有，真是炸缸了，数据库整垮。 解决措施： 避免非法请求 缓存默认值或空值 使用布隆过滤器判断数据是否存在于数据库中 后台在向数据库添加数据时，会将该数据保存至布隆过滤器中。后续大量请求则只会访问redis和布隆过滤器而不会访问数据库 高可用 如果只有一个redis节点，若异常宕机了，虽然可用持久化机制恢复数据，但是恢复数据的这段过程中，redis是不可用的。而且，如果这台机器磁盘损坏，那将造成数据无法恢复的情况。为此，应当部署多个redis节点，保证数据安全性与redis的高可用性。 ","date":"0001-01-01","objectID":"/redis/:8:0","tags":null,"title":"","uri":"/redis/"},{"categories":null,"content":"主从复制 设置一主多从的节点模式，主节点复制数据的写入与同步数据给从节点，从节点复制数据的读取。 replicaof \u003c目标服务器的IP\u003e \u003c目标服务器redis的端口\u003e 让目标服务器作为主节点 ","date":"0001-01-01","objectID":"/redis/:9:0","tags":null,"title":"","uri":"/redis/"},{"categories":null,"content":"第一次同步 从节点与主节点建立连接 发送psync ? -1 给主节点。? 表示主节点的runId,-1表示offset 复制进度。由于是第一次同步，所以都是未知数。不过主节点收到该命令后,会用fullresync {runId} {offset} 返回给从节点，告知其runId和offset 主节点发送RDB文件给从节点（全量复制） 从节点先清除redis数据库内的数据，再执行RDB文件 在以下三个时间点，产生的写操作命令都为新写操作命令，会被加入replication buffer缓存区。 主节点生成RDB文件的过程 主节点发送RDB文件的过程 从节点执行RDB文件的过程 主节点将新写操作命令发送给从节点（增量复制） 主节点将replication buffer缓存区中的新写操作命令发送给从节点，完成增量数据的同步。 ","date":"0001-01-01","objectID":"/redis/:9:1","tags":null,"title":"","uri":"/redis/"},{"categories":null,"content":"命令传播 当主从节点完成第一次同步之后，双方会维护一个TCP连接，这个连接是长连接，目的是避免频繁的TCP连接与断开带来的性能开销。 此后，主节点通过这个连接将新的写操作命令发送给从节点，然后从节点执行命令，达到主从数据一致。 Redis 主节点每次收到写命令之后，先写到内部的缓冲区（replication buffer），然后异步发送给从节点。 ","date":"0001-01-01","objectID":"/redis/:9:2","tags":null,"title":"","uri":"/redis/"},{"categories":null,"content":"分摊主服务器的压力 背景：当一个主节点拥有很多从节点时，那么主节点会忙于使用fork()创建子进程，如果主节点的内存数据非常大，执行fork()函数时是会阻塞主节点的，从而使得redis无法正常处理请求。另外，传输RDB文件也会占用主节点的网络带宽，会对主节点响应命令请求产生影响。 概括为以下两点： 忙于执行fork()造成主节点阻塞 占用主节点网络带宽 解决方案 让有从节点的从节点也做为“主节点”，它负责对它的从节点进行同步，主节点只要负责对一级从节点同步即可。 ","date":"0001-01-01","objectID":"/redis/:9:3","tags":null,"title":"","uri":"/redis/"},{"categories":null,"content":"增量复制 背景：由于网络波动造成主从节点之间的TCP长连接端口，那么这个过程中主节点执行了新的写操作命令，而从节点无法同步的情况，造成从节点读取的还是旧数据。 redis如何解决的？ 当连接恢复时，从节点发送pysnc {runId} {offset}命令给主节点，由于不是第一次同步，此时offset不为-1，那么主节点会反馈continue命令告诉从节点接下来要采用增量复制的方式同步数据，然后将断线期间的增量数据发送给从节点。 runId：是每个redis节点启动时生成的唯一标识 offset：表示复制的进度 首先要知道哪些是增量数据，通过以下两个东西实现： repl_backlog_buffer：是一个环形缓存区当主节点通过命令传播发送给从节点时，同时也会存入到该缓存区内。 replication offset：标记上面这个缓存区的同步进度。主节点使用master_repl_offset 来记录自己写到的位置，从节点使用 slave_repl_offset来记录自己读到的位置。 示意图 由于repl_backlog_buffer 是一个环形缓存区域，写满后会覆盖之前的数据。那么此时要保证数据的一致性的话就不得不采取**全量复制（将RDB文件传送给从节点）**了。 如何判断环形缓存区域发生了数据的覆盖？ 如果从节点要读取的数据已经不在repl_backlog_buffer 缓存区内，则说明发送了数据的覆盖，应当采取全量复制进行数据同步。 所以应当尽可能减少数据覆盖的可能性，就要增加repl_backlog_buffer缓冲区的大小。 经验大小： second * write_size_per_second second 为从服务器断线后重新连接上主服务器所需的平均 时间(以秒计算)。 write_size_per_second 则是主服务器平均每秒产生的写命令数据量大小。 ","date":"0001-01-01","objectID":"/redis/:9:4","tags":null,"title":"","uri":"/redis/"},{"categories":null,"content":"哨兵模式 ","date":"0001-01-01","objectID":"/redis/:10:0","tags":null,"title":"","uri":"/redis/"},{"categories":null,"content":"为什么要有哨兵模式 因不可抗因素主节点挂掉时，客户端对redis的使用就会出现异常，无法写入新的数据。那么此时，就要人工涉入，选一个从节点做为新的主节点，并通知客户端将其配置的主节点ip地址更新为新主节点的ip地址。显然，这很不智能。 redis提供了哨兵模式，用于实现主从节点故障转移，它会监测主节点是否存活，如果挂了会选举一个从节点作为新主节点，并且将新主节点的信息通知给从节点和客户端。 哨兵的三个核心功能：监控、选主、通知 ","date":"0001-01-01","objectID":"/redis/:10:1","tags":null,"title":"","uri":"/redis/"},{"categories":null,"content":"如何判断主节点真的故障了 哨兵也是一个redis节点。 哨兵节点通过每隔1s给主从节点发送ping命令，如果有节点未在规定时间内给出响应，哨兵会认为该节点主观下线。 但是没在规定时间内给出响应，不能断定这个节点挂了。比如主节点可能由于系统压力比较大或者网络发生了阻塞，导致主节点未能在规定时间内相应哨兵节点的ping命令。所以，不能只由一个哨兵节点的判断就觉得主节点是否挂了，那么就需要一个哨兵集群，当一个哨兵认为主节点主观下线时，会通知剩余的哨兵，他们会根据自己与主节点的网络连接状况表示赞同与不赞同。当半数以上（quorum 设置具体几个，合理设置为哨兵数量+1/2）的节点都赞同主节点挂了，就会认为主节点客观下线。 为保证不出现赞同/不赞同票数一致的情况，哨兵集群应对搭建奇数个节点。 ","date":"0001-01-01","objectID":"/redis/:10:2","tags":null,"title":"","uri":"/redis/"},{"categories":null,"content":"由哪个哨兵进行主从故障转移 哨兵之中需要选出一个leader来进行主从故障转移的操作。 先认为主节点主观下线的哨兵是候选者，所谓候选者，就是想当leader的节点。 候选者需要达到以下两个条件才能成为leader： 得到投票的数量为哨兵数量的半数以上 拿到的票数大于等于哨兵配置文件中的quorum 具体流程： 哨兵A先发现主节点挂了，那么它就是候选者。随后会通知其它的哨兵，看看它们的意见。其它哨兵根据自己与主节点网络连接的情况来表示赞同或不赞同，当赞同数量达到quorum（通常设置为节点数量+1/2），则会认为主节点主观下线。然后，需要选举一个leader来进行主从故障转移。 哨兵A首先会给自己一票（只有候选者能给自己投票），然后像其它哨兵发送投票请求，就是想让别的哨兵投票给自己。其它哨兵收到投票请求后，并且自己的投票次数还在，则会把自己的一票投给它。最终若哨兵A拿到哨兵数量半数以上的票数，且这个票数也大于quorum，那么哨兵A会成为leader节点，准备进行主从故障转移操作。 特殊情况： 那如果同时有两个哨兵认为主节点挂了呢？此时两个哨兵都会先给自己投上一票，然后会向其它哨兵节点发送投票请求。此时就看别的哨兵先收到谁的投票请求就投票给谁，若哨兵投票次数没有了就得不到投票。 ","date":"0001-01-01","objectID":"/redis/:10:3","tags":null,"title":"","uri":"/redis/"},{"categories":null,"content":"主从故障转移过程 步骤一 选出一个新的主节点。 首先要过滤掉一些下线以及历史网络状况问题出现多的从节点，避免它们成为新主节点时由于网络问题挂了又要选新主节点。redis配置文件中会记录网络延迟大于一定次数的节点，这些节点会被认为不适合当主节点 选主节点决策三大点： 优先级 \u003e 复制进度 \u003e id号小的从节点胜出 在第一轮比较优先级时就可以选出主节点，若有不止一个优先级相同的主节点则会进行下一轮的比较，以此类推。 下面说明各个点表示的具体含义： 优先级 slave-priority 可以自主配置。可以根据哪台机器内存大速度快就设置其优先级高，在将来发生主从故障转移时，优先选择作为新主节点 复制进度 就是比较在环形缓存区中从节点的要读位置，离主节点要写的位置越近，说明复制最完全。复制程度高的当新主节点 步骤二 让从节点认新的主节点。也就是修改复制目标。 哨兵向从节点发送SLAVEOF命令实现让从节点认新的主节点 步骤三 通知客户端主节点ip发生了变化，需要重新配置 通过redis的发布者/订阅者机制实现。每个哨兵提供发布者/订阅者机制，客户端可以从哨兵订阅消息。 哨兵提供的消息订阅频道有很多，不同频道包含了主从节点中不同的关键事件，几个常见的如下： 主从节点完成切换后，哨兵就会向**+switch-master**频道发布新主节点的ip和端口的消息，这个时候客户端可以收到这条消息，重新配置新主节点的ip和端口。 步骤四 旧主节点挂了之后，哨兵集群仍然会一直监控主节点的状态。当旧主节点恢复时，需要将其设置成从节点，认新主节点。 当旧主节点恢复时，哨兵集群发送SLAVEOF命令完成旧主节点认新主节点的过程 ","date":"0001-01-01","objectID":"/redis/:10:4","tags":null,"title":"","uri":"/redis/"},{"categories":null,"content":"哨兵集群如何组成 也是通过redis的发布者/订阅者机制。 对于哨兵的配置，只需要sentinel monitor \u003cmaster-name\u003e \u003cip\u003e \u003credis-port\u003e \u003cquorum\u003e 一行即可。 配置完后，哨兵会订阅主节点上的__sentinel__频道，各个哨兵会把自己的ip地址和端口发送到该频道中，其它哨兵可以从频道中读取消息发现其它的哨兵。这样一来哨兵集群就形成了。 那对从节点怎么监控呢？ 哨兵通过以10s一次频率像主节点发送info命令，主节点会返回从节点列表。接着哨兵就可以根据从节点列表中的连接信息与每个从节点建立连接，并在这个连接上进行持续的监控。 ","date":"0001-01-01","objectID":"/redis/:10:5","tags":null,"title":"","uri":"/redis/"}]