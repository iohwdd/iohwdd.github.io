# 

***

title = 'Mysql'
date = 2024-11-19T22:02:00+08:00
draft = true

+++



# 索引

innodb存储数据：

以数据页的形式存储，数据页内拆分了若干组，组的引入是为了建立页目录，页目录记录的就是各个组的主键最大的位置，达到快速定位的效果。



b+树存储数据

每一个节点是一个数据页，只有叶子节点存放数据，非叶子节点存放目录项作为索引



Q：为什么采用B+数作为索引

A：

普通二叉树在极端情况下变成链表，查询效率低。
平衡二叉树和红黑树随着数据量的增加，树的高度也会增加，因此会增加磁盘IO，影响整体查询效率。

然后相比b树（多叉树）呢，b+树具有以下特点

1. 只有叶子节点才会存放实际数据，非叶子节点只存放索引
2. 所有索引都会在叶子节点出现，叶子节点直接构成一个有序链表（凭此就天然适合范围查询）
3. 非叶子节点有多少个子节点就有多少索引。
4. 非叶子节点也会存在子节点中，且是子节点中所有索引的最小（或最大）

对于使用情况：

1. 单点查询
   b+树非叶子节点只存放索引，在相同数据量的情况下，相比b树既存索引又存数据，b+树的非叶子节点可以存放更多的索引，因此b+树比b树更**矮胖**，查询底层节点的磁盘IO次数少（树低，深度浅）。
2. 插入和删除效率
   由于b+树存在大量的冗余节点，删除一个节点的时候，可以直接从叶子节点删除。而b树，删除一个节点可能会导致树结构的复制变化。对于插入也一样，有冗余节点，可能存在节点的分裂（如果节点饱和），但是最多只涉及一条路径。而且b+树自动平衡，不需要复杂的算法，类似红黑树的旋转操作等。因此b树的插入删除效率更高
3. 范围查询
   b+树的所有叶子节点有一个链表进行连接，且是有序的，支持范围查询





聚簇索引（通常为主键索引），叶子确定存放的是数据；而二级索引，叶子节点存放的是主键值，所以通过二级索引查数据时，还需要通过查找到的主键值，再根据主键索引（聚簇索引）找到数据，这就是**回表**操作。



**覆盖索引**：

当使用联合索引查询时，若需要查询的字段都包含在联合索引中，则不需要进行回表操作，直接就能够返回想要的数据。

# 事务

四大特性：原子性（undo kog）、一致性、隔离性（MVCC）、持久性（redo log）

并行事务可能产生的问题：脏读、不可重复读、幻读

隔离级别：读未提交、读已提交、可重复读、串行化

MVCC（多版本并发控制），维护一个**版本链**，实现读已提交与可重复读

innodb通过Read View实现MVCC

Read View：

记录四个字段

1. 事务id  -> creator_trx_id
2. 当前活跃但未提交的事务id列表 -> m_ids
3. 活跃且月提交事务中最小的事务id -> min_trx_id
4. 未来分配给新事务的事务id -> max_trx_id

![image-20241114194452324](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20241114194452324.png)

记录的更新，会通过undo log形成一个版本链，链中每条记录都记录了事务的id。通过找到小于min_trx_id的第一条记录即可能到最新的且是已提交事务的记录。



可重复读是在事务开启时创建一个Read View，一直沿用到事务结束

而读提交则是每在执行select语句之前都会更新一次Read View，这样就可以确保能够读到新的已提交的事务。

# 锁

全局锁：整个数据库只能读了

表级锁：

1. 表锁
2. 元数据锁 -> 锁的是表结构，读时不能改，改时不能读
3. 意向锁
   在给行数据加上共享锁/独占锁时，都要先给表加上意向共享/独占锁。所以，这个锁可以快速判断表记录是否还要共享/独占锁

行级锁：

1. record lock 记录锁
   顾名思义，对某一条记录加锁，有共享锁与独占锁之分

2. gap lock 间隙锁

   对一个范围内加锁，是开区间

3. next-key 临键锁

   对一个范围内加锁，左开右闭，可以理解为间隙锁+记录锁

4. 插入意向锁

   当想在间隙锁范围内插入数据，就会生成插入意向锁，会阻塞等待直到间隙锁释放，再插入数据

间隙锁与临键锁是为了**解决幻读**问题而引出的。

如何加行级锁？分下面几种情况

唯一索引等值查询：

1. 记录存在。临键锁退化成记录锁，因为此时仅凭记录锁即可避免幻读问题，由于唯一索引的主键冲突机制，保证数据唯一性，然后加记录锁可以避免其它事务去删除该记录
2. 记录不存在。临键锁退化成间隙锁。区间范围为恰好能包裹住改记录的区间，如查找id=2，且不存在，然后数据库中只有id=1与id=5的数据，那么区间就是（1，5），能包裹住2

唯一索引范围查询

非唯一索引等值查询

非唯一索引范围查询

# 日志

三种日志：undo log、redo log、bin log

## undo log 

主要是用来实现事务的原子性，用于事务回滚与MVCC。

比如进行一条更新操作语句时，在更新之前（事务提交前）会把旧数据写入undo log日志文件，如果事务出现异常，可以根据该日志文件进行回滚。



buffer pool 

基于内存的缓存区

读取数据时，会从磁盘中读取数据页到内存中，在内存中修改完后不会直接写回磁盘，而是会将**数据页**缓存在inno存储引擎中的buffer pool中，记作缓存页。此时缓存页与磁盘中的数据并不一致，变为脏页。

innoDB引擎会在适当的时候将脏页刷新到磁盘中，这就是WAL技术，写操作不会立即写到磁盘上，而是先写日志，后面在合适的时机再写到磁盘上。

这样可以提高数据库的读写性能（减少磁盘IO）。

这个缓存区不仅仅只缓存数据页，还包括了索引页，undo页等，下面是该缓存区的内存模型：

![image-20241113201223864](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20241113201223864.png)

## redo log 

主要是用于实现事务的持久性，在系统故障如停电，恢复后能够恢复数据。在**事务提交后**，都会向该日志记录**数据页进行了什么操作**，像XXX数据库对XXX表进行了XXX操作这种详细操作信息。



产生的redo log不会立即写入磁盘，会先写入redo log buffer，后续再持久化到磁盘中

有这么几个写入磁盘的时机（刷盘时机）：

1. mysql正常关闭
2. redo log buffer写入量大于内存空间的一般
3. 后台线程每隔1s （这种情况对应`innodb_flush_log_at_trx_commit = 0 或 2`
4. 事务提交后（这种情况对应`innodb_flush_log_at_trx_commit = 1`

参数为0：

每次事务提交时，不做操作。1s后，OS通过调用write()写入page cache，然后调用fsync()持久化到磁盘

参数为2：

每次事务提交时，将redo log buffer里的redo log 写入 page cache。1s后，调用fsync()持久化到磁盘



**写入方式**

四个首尾相连的日志文件，循环写，已刷盘的部分会擦除。

因此redo log日志文件上始终保持的是未刷盘的日志（也就是说脏页数据还每更新到磁盘）。
在mysql服务宕机的情况下，恢复启动时可直接执行redo log上未刷盘的日志，达到数据恢复的目的。



Q：为什么bin log日志不能用于mysql宕机后进行数据恢复
A：bin log是不知道哪些数据是要恢复的，不知道从哪里开始。而redo log，对于那些未刷盘的日志，就是尚未更新至磁盘中的数据，也就是要恢复的数据。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/checkpoint.png)



## bin log

用Mysql里Server层产生的日志，主要用于数据备份和主从复制，上面两种日志都是基于innodb引擎的。

跟redo log有什么区别？

1. 写入方式不同
   redo循环写，只保存未被刷盘的脏页日志

   bin追加写，写满了新建一个文件继续写。也就是说这个日志保存了所有的mysql变化，这样当然可以用来数据备份、主从复制了（从节点同步时，都会先情况从节点的数据，再根据bin log日志文件进行复制）

2. 用途不同

   一个用于崩溃恢复

   一个同于数据备份、主从复制

bin log不能拆开，必须保证一次性写入。

mysq为每个线程都会引入一个bin log cache，在事务提交时，会把每个线程bin log cache完整写入（通过OS里的wirte）到bin log文件并清空bin log cache。后续os再调用fsync()持久化到磁盘



**三种文件格式**

1. statement（默认）
   记录每一条**修改数据的SQL**。主从同步根据SQL语句重现。
   存在的问题：若记录的SQL含有动态函数，如now()，当在从库运行时结果会与主库中的数据不一致
2. row
   记录**行数据**的变化。
   存在的问题：若一条update语句批量更新了好多行的数据，那么该文件格式下会记录**每一行**的数据变化，导致binlog文件过大
3. mixed
   上述两种混合。
   根据不同的情况自动使用statement模式或row模式



**写入方式**

追加写，写满一个就创建新的文件写。保存的是全量的日志。



## 两阶段提交

如何保证 MySQL 宕机后 redolog 与 binlog 都写入到本地？
因为 redolog 与 binlog 是两个独立的运行逻辑，宕机时可能存在一方写入成功一方还未来得及写入的情况。MySQL 解决这种情况引入了**两阶段提交**
当事务提交时，MySQL 内部会开启一个 xa 事务，分两阶段完成 xa 事务的提交
1.准备阶段。先让 redolog 写入磁盘后，通知 MySQL server 成功了
2.提交阶段。先让 binlog 写入磁盘后，通知 MySQL server 成功了，接着将 redolog 日志状态设置为 commit，最后通知 MySQL server 都写入成功了

